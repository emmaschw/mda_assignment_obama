{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40611347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD CAPTIONS\n",
    "\n",
    "from pprint import pprint\n",
    "from gensim.models import CoherenceModel\n",
    "from wordcloud import WordCloud\n",
    "from collections import Counter\n",
    "import matplotlib.colors as mcolors\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models as LDAgensim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab06805",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b22ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We construct our LDA model\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "model = gensim.models.ldamodel.LdaModel(corpus=corpus, id2word=id2word, num_topics = 6, \n",
    "                                            random_state = 100, update_every = 1, chunksize = 100, passes = 14, alpha = 'auto', per_word_topics=True) # Here we selected 5 topics\n",
    "pprint(model.print_topics())\n",
    "model_cor = model[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04dce1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we calculate coherence score and perplexity\n",
    "\n",
    "model_coher = CoherenceModel(model=model, texts=cleaned_data, dictionary=id2word, coherence='c_v')\n",
    "coher_s = model_coher.get_coherence()\n",
    "print('Coherence Score: ', coherence_lda)\n",
    "print('Perplexity: ', model.log_perplexity(corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd2dbda",
   "metadata": {},
   "source": [
    "To find the most important words for each topic, we first find the dominant topics by taking the distribution of the topics per document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9927f8c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'corpus' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4312/297667508.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdom\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_document_topics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mminimum_probability\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'corpus' is not defined"
     ]
    }
   ],
   "source": [
    "topic_dist = [model.get_document_topics(item, minimum_probability=0.0) for item in corpus]\n",
    "topic_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52220a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_cor = [sorted(topics, key=lambda record: -record[1])[0] for topics in topic_dist]\n",
    "top_cor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc216b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.num_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d89199e",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = [[(term, round(wt, 3)) for term, wt in model.show_topic(n, topn=20)] for n in range(0, model.num_topics)]\n",
    "topics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11223f4f",
   "metadata": {},
   "source": [
    "Next, we construct a dataframe matrix for the topics and keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7737969d",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_mat = pd.DataFrame([[term for term, wt in topic] for topic in topics], columns = ['Keyword '+str(i) for i in range(1, 21)],\n",
    "                         index=['Topic '+str(t) for t in range(1, model.num_topics+1)]).T\n",
    "topics_mat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889508a4",
   "metadata": {},
   "source": [
    "The keywords per topic are now viewable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be25c15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', -1)\n",
    "\n",
    "topics_mat = pd.DataFrame([', '.join([term for term, wt in topic]) for topic in topics], columns = ['Topic Keywords'],\n",
    "                         index=['Topic'+str(t) for t in range(1, model.num_topics+1)] )\n",
    "topics_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90973437",
   "metadata": {},
   "source": [
    "### Wordcloud"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89276fe",
   "metadata": {},
   "source": [
    "We construct a wordcloud for our LDA model from the keywords for each topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be4e53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cloud = WordCloud(background_color=\"white\", colormap=\"Dark2\",\n",
    "               max_font_size=150, random_state=42)\n",
    "plt.rcParams['figure.figsize'] = [20, 10]\n",
    "\n",
    "# We also construct subplots per topic\n",
    "for i in range(model.num_topics): # this is how many topics we show the wordclouds for\n",
    "\n",
    "    cloud.generate(text=topics_mat[\"Topic Keywords\"][i])\n",
    "    \n",
    "    plt.subplot(2, 3, i+1)\n",
    "    plt.imshow(wc, interpolation=\"bilinear\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(topics_mat.index[i])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012229d9",
   "metadata": {},
   "source": [
    "### Word count and word weights or significance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5bdb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we create the data frame for the word count and keyword weights \n",
    "tops = model.show_topics(formatted=False)\n",
    "flat_data = [w for w_list in cleaned_data for w in w_list]\n",
    "counts = Counter(flat_data)\n",
    "\n",
    "output = []\n",
    "for i, topic in tops:\n",
    "    for word, weight in topic:\n",
    "        output.append([word, i , weight, counter[word]])\n",
    "\n",
    "df = pd.DataFrame(out, columns=['word', 'topic_id', 'weights', 'word_count'])        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4265c13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we plot the word count and the keyword weights\n",
    "fig, axes = plt.subplots(2, 3, figsize=(16,10), sharey=True, dpi=160)\n",
    "colors = [color for name, color in mcolors.TABLEAU_COLORS.items()]\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    ax.bar(x='word', height=\"word_count\", data=df.loc[df.topic_id==i, :], color=colors[i], width=0.5, alpha=0.3, label='Word Count')\n",
    "    axtwin = ax.twinx()\n",
    "    axtwin.bar(x='word', height=\"weights\", data=df.loc[df.topic_id==i, :], color=colors[i], width=0.2, label='Weights')\n",
    "    ax.set_ylabel('Word Count', color=colors[i])\n",
    "    ax_twin.set_ylim(0, 0.030); ax.set_ylim(0, 3500)\n",
    "    ax.set_title('Topic: ' + str(i), color=colors[i], fontsize=16)\n",
    "    ax.tick_params(axis='y', left=False)\n",
    "    ax.set_xticklabels(df.loc[df.topic_id==i, 'word'], rotation=30, horizontalalignment= 'right')\n",
    "    ax.legend(loc='upper left'); axtwin.legend(loc='upper right')\n",
    "\n",
    "fig.tight_layout(w_pad=2)    \n",
    "fig.suptitle('Word Count and Weights of Topic Keywords', fontsize=22, y=1.05)    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282f0d8b",
   "metadata": {},
   "source": [
    "### We investigate the number of speeches corresponding to a topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204dc7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def speeches_per_topic (model, corpus, start=0, end=1):\n",
    "    full_corpus = corpus[start:end]\n",
    "    domtopics = []\n",
    "    percentage_topic = []\n",
    "    for i, corp in enumerate(full_corpus):\n",
    "        topic_percs, wordid_topics, wordid_phivalues = model[corp]\n",
    "        dominant_topic = sorted(topic_percs, key = lambda x: x[1], reverse=True)[0][0]\n",
    "        dominant_topics.append((i, dominant_topic))\n",
    "        percentage_topic.append(topic_percs)\n",
    "    return(dominant_topics, percentage_topic)\n",
    "\n",
    "domtopics, percentage_topic = topics_per_document(model=lda_model, corpus=corpus, end=-1)            \n",
    "\n",
    "# Dominant Topics per speech\n",
    "df = pd.DataFrame(domtopics, columns=['Document_Id', 'Dominant_Topic'])\n",
    "speech_dom_top = df.groupby('Dominant_Topic').size()\n",
    "df_speech_dom_top = speech_dom_top.to_frame(name='count').reset_index()\n",
    "\n",
    "# Distribution of topics by weight\n",
    "doc_weight = pd.DataFrame([dict(t) for t in percentage_topic])\n",
    "df_doc_weight = doc_weight.sum().to_frame(name='count').reset_index()\n",
    "\n",
    "# 3 main keywords per topic\n",
    "keywords3 = [(i, topic) for i, topics in model.show_topics(formatted=False) \n",
    "                                 for j, (topic, wt) in enumerate(topics) if j < 3]\n",
    "\n",
    "stacked_df_keywords3 = pd.DataFrame(keywords3, columns=['topic_id', 'words'])\n",
    "df_keywords3 = stacked_df_keywords3.groupby('topic_id').agg(', \\n'.join)\n",
    "df_keywords3.reset_index(level=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a0d223",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot speeches per dominant topic\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 10), dpi=120, sharey=True)\n",
    "\n",
    "# Dominant topic distribution\n",
    "ax1.bar(x='Dominant_Topic', height='count', data=df_speech_dom_top, width=.5, color='firebrick')\n",
    "ax1.set_xticks(range(df_speech_dom_top.Dominant_Topic.unique().__len__()))\n",
    "formatter = FuncFormatter(lambda x, pos: 'Topic ' + str(x)+ '\\n' + df_keywords3.loc[df_keywords3.topic_id==x, 'words'].values[0])\n",
    "ax1.xaxis.set_major_formatter(formatter)\n",
    "ax1.set_title('Speeches by dominant topic', fontdict=dict(size=10))\n",
    "ax1.set_ylabel('Speeches')\n",
    "ax1.set_ylim(0, 1000)\n",
    "\n",
    "# Topic weights distribution\n",
    "ax2.bar(x='index', height='count', data=df_doc_weight, width=.5, color='steelblue')\n",
    "ax2.set_xticks(range(df_doc_weight.index.unique().__len__()))\n",
    "ax2.xaxis.set_major_formatter(formatter)\n",
    "ax2.set_title('Speeches by topic weights', fontdict=dict(size=10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d4d7bf",
   "metadata": {},
   "source": [
    "### LDA interactive visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7117968b",
   "metadata": {},
   "source": [
    "Shows the topics and their keywords. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126d1d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.enable_notebook()\n",
    "interactive = gensimvis.prepare(model, corpus, id2word)\n",
    "interactive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99fb203",
   "metadata": {},
   "source": [
    "### Speech dominant topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78af2386",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cor = pd.DataFrame()\n",
    "df_cor['Dominant Topic'] = [item[0]+1 for item in df_cor]\n",
    "df_cor['Contribution %'] = [round(item[1]*100, 2) for item in df_cor]\n",
    "df_cor['Topic Terms'] = [lda_topics_df.iloc[t[0]]['Key_Words_per_Topic'] for t in df_cor]\n",
    "\n",
    "df_cor.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65cd13c",
   "metadata": {},
   "source": [
    "### Percentages of dominant topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c65865",
   "metadata": {},
   "outputs": [],
   "source": [
    "dom_df = df_cor.groupby('Dominant Topic').agg(\n",
    "                                  Doc_Count = ('Dominant Topic', np.size),\n",
    "                                  Total_Docs_Perc = ('Dominant Topic', np.size)).reset_index()\n",
    "\n",
    "dom_df['Total speech %'] = dom_df['Total speech %'].apply(lambda row: round((row*100) / len(corpus), 2))\n",
    "\n",
    "dom_df.sort_values('Total speech %')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f60f8c",
   "metadata": {},
   "source": [
    "### LDA weights by topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8a4204",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = pd.DataFrame.from_records([{v: k for v, k in row} for row in topic_dist])\n",
    "weights.columns = ['Topic ' + str(i) for i in range(1,8)]\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78817023",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = speech.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27d4258",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['year'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af10921",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights['year'] = df2.year.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80c54ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46746d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights['prevalent'] = weights.drop('year', axis=1).idxmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf80c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights.head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65dea4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights.groupby('year')['prevalent'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635d1a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_dominance = weights.groupby('year')['prevalent'].value_counts(normalize=True).unstack().fillna(0)\n",
    "weight_dominance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2c295c",
   "metadata": {},
   "source": [
    "### LDA Topic Distribution from 2004 to 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a85f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_dom_year = weights.groupby('year')['prevalent'].value_counts(normalize=True).unstack().fillna(0).reset_index().copy()\n",
    "weight_dom_year.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9f9e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_melted_year = weight_dom_year.melt(id_vars= 'year' , value_vars=['Topic ' + str(i) for i in [1,2, 3, 4, 5, 6]], var_name='Topic', value_name='prevelance')\n",
    "weight_melted_year"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f107080",
   "metadata": {},
   "source": [
    "### ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46157cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_melted_year.to_excel(\"/Users/fazek/OneDrive/Asztali gÃ©p/mda 2022/topic_trend.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58cb1f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "_ = sns.lineplot(data=df_melted_year, x=\"year\", y=\"prevelance\", hue=\"Topic\", style=\"Topic\", palette='Dark2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa62b868",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e022f74d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6867c620",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9bce534",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7a84d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc833200",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c8da53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c851bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a23703",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
