{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21aba99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD CAPTIONS\n",
    "\n",
    "from pprint import pprint\n",
    "from gensim.models import CoherenceModel\n",
    "from wordcloud import WordCloud\n",
    "from collections import Counter\n",
    "import matplotlib.colors as mcolors\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models as LDAgensim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6527a5a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbaa3b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We construct our LDA model\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "model = gensim.models.ldamodel.LdaModel(corpus=corpus, id2word=id2word, num_topics = 6, \n",
    "                                            random_state = 100, update_every = 1, chunksize = 100, passes = 14, alpha = 'auto', per_word_topics=True) # Here we selected 5 topics\n",
    "pprint(model.print_topics())\n",
    "model_cor = model[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c349687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we calculate coherence score and perplexity\n",
    "\n",
    "model_coher = CoherenceModel(model=model, texts=cleaned_data, dictionary=id2word, coherence='c_v')\n",
    "coher_s = model_coher.get_coherence()\n",
    "print('Coherence Score: ', coherence_lda)\n",
    "print('Perplexity: ', model.log_perplexity(corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96799b33",
   "metadata": {},
   "source": [
    "To find the most important words for each topic, we first find the dominant topics by taking the distribution of the topics per document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5725543f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'corpus' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4312/297667508.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdom\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_document_topics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mminimum_probability\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'corpus' is not defined"
     ]
    }
   ],
   "source": [
    "topic_dist = [model.get_document_topics(item, minimum_probability=0.0) for item in corpus]\n",
    "topic_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da1347b",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_cor = [sorted(topics, key=lambda record: -record[1])[0] for topics in topic_dist]\n",
    "top_cor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40990ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.num_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3244c6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = [[(term, round(wt, 3)) for term, wt in model.show_topic(n, topn=20)] for n in range(0, model.num_topics)]\n",
    "topics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05be2d1a",
   "metadata": {},
   "source": [
    "Next, we construct a dataframe matrix for the topics and keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54912e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_mat = pd.DataFrame([[term for term, wt in topic] for topic in topics], columns = ['Keyword '+str(i) for i in range(1, 21)],\n",
    "                         index=['Topic '+str(t) for t in range(1, model.num_topics+1)]).T\n",
    "topics_mat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58aa1e65",
   "metadata": {},
   "source": [
    "The keywords per topic are now viewable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14913ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', -1)\n",
    "\n",
    "topics_mat = pd.DataFrame([', '.join([term for term, wt in topic]) for topic in topics], columns = ['Topic Keywords'],\n",
    "                         index=['Topic'+str(t) for t in range(1, model.num_topics+1)] )\n",
    "topics_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb118006",
   "metadata": {},
   "source": [
    "Wordcloud"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06b3d1f",
   "metadata": {},
   "source": [
    "We construct a wordcloud for our LDA model from the keywords for each topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88be4c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "cloud = WordCloud(background_color=\"white\", colormap=\"Dark2\",\n",
    "               max_font_size=150, random_state=42)\n",
    "plt.rcParams['figure.figsize'] = [20, 10]\n",
    "\n",
    "# We also construct subplots per topic\n",
    "for i in range(model.num_topics): # this is how many topics we show the wordclouds for\n",
    "\n",
    "    cloud.generate(text=topics_mat[\"Topic Keywords\"][i])\n",
    "    \n",
    "    plt.subplot(2, 3, i+1)\n",
    "    plt.imshow(wc, interpolation=\"bilinear\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(topics_mat.index[i])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fefed11",
   "metadata": {},
   "source": [
    "Word count and word weights or significance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69b59c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cecba4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we create the data frame for the word count and keyword weights \n",
    "tops = model.show_topics(formatted=False)\n",
    "flat_data = [w for w_list in cleaned_data for w in w_list]\n",
    "counts = Counter(flat_data)\n",
    "\n",
    "output = []\n",
    "for i, topic in tops:\n",
    "    for word, weight in topic:\n",
    "        output.append([word, i , weight, counter[word]])\n",
    "\n",
    "dataframe = pd.DataFrame(out, columns=['word', 'topic_id', 'weights', 'word_count'])        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7738ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we plot the word count and the keyword weights\n",
    "fig, axes = plt.subplots(2, 3, figsize=(16,10), sharey=True, dpi=160)\n",
    "colors = [color for name, color in mcolors.TABLEAU_COLORS.items()]\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    ax.bar(x='word', height=\"word_count\", data=dataframe.loc[dataframe.topic_id==i, :], color=colors[i], width=0.5, alpha=0.3, label='Word Count')\n",
    "    axtwin = ax.twinx()\n",
    "    axtwin.bar(x='word', height=\"weights\", data=dataframe.loc[df.topic_id==i, :], color=colors[i], width=0.2, label='Weights')\n",
    "    ax.set_ylabel('Word Count', color=colors[i])\n",
    "    ax_twin.set_ylim(0, 0.030); ax.set_ylim(0, 3500)\n",
    "    ax.set_title('Topic: ' + str(i), color=colors[i], fontsize=16)\n",
    "    ax.tick_params(axis='y', left=False)\n",
    "    ax.set_xticklabels(dataframe.loc[dataframe.topic_id==i, 'word'], rotation=30, horizontalalignment= 'right')\n",
    "    ax.legend(loc='upper left'); axtwin.legend(loc='upper right')\n",
    "\n",
    "fig.tight_layout(w_pad=2)    \n",
    "fig.suptitle('Word Count and Weights of Topic Keywords', fontsize=22, y=1.05)    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f122a942",
   "metadata": {},
   "source": [
    "We investigate the number of speeches corresponding to a topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e4cf08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def speeches_per_topic (model, corpus, start=0, end=1):\n",
    "    full_corpus = corpus[start:end]\n",
    "    domtopics = []\n",
    "    percentage_topic = []\n",
    "    for i, corp in enumerate(full_corpus):\n",
    "        topic_percs, wordid_topics, wordid_phivalues = model[corp]\n",
    "        dominant_topic = sorted(topic_percs, key = lambda x: x[1], reverse=True)[0][0]\n",
    "        dominant_topics.append((i, dominant_topic))\n",
    "        percentage_topic.append(topic_percs)\n",
    "    return(dominant_topics, percentage_topic)\n",
    "\n",
    "domtopics, percentage_topic = topics_per_document(model=lda_model, corpus=corpus, end=-1)            \n",
    "\n",
    "# Dominant Topics per speech\n",
    "dataframe = pd.DataFrame(domtopics, columns=['Document_Id', 'Dominant_Topic'])\n",
    "speech_dom_top = df.groupby('Dominant_Topic').size()\n",
    "df_speech_dom_top = speech_dom_top.to_frame(name='count').reset_index()\n",
    "\n",
    "# Distribution of topics by weight\n",
    "doc_weight = pd.DataFrame([dict(t) for t in percentage_topic])\n",
    "df_doc_weight = doc_weight.sum().to_frame(name='count').reset_index()\n",
    "\n",
    "# 3 main keywords per topic\n",
    "keywords3 = [(i, topic) for i, topics in model.show_topics(formatted=False) \n",
    "                                 for j, (topic, wt) in enumerate(topics) if j < 3]\n",
    "\n",
    "stacked_df_keywords3 = pd.DataFrame(keywords3, columns=['topic_id', 'words'])\n",
    "df_keywords3 = stacked_df_keywords3.groupby('topic_id').agg(', \\n'.join)\n",
    "df_keywords3.reset_index(level=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b00340",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOT DONE YET\n",
    "# Plot speeches per dominant topic\n",
    "#fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 10), dpi=120, sharey=True)\n",
    "\n",
    "# Topic Distribution by Dominant Topics\n",
    "#ax1.bar(x='Dominant_Topic', height='count', data=df_dominant_topic_in_each_doc, width=.5, color='firebrick')\n",
    "#ax1.set_xticks(range(df_dominant_topic_in_each_doc.Dominant_Topic.unique().__len__()))\n",
    "#tick_formatter = FuncFormatter(lambda x, pos: 'Topic ' + str(x)+ '\\n' + df_top3words.loc[df_top3words.topic_id==x, 'words'].values[0])\n",
    "#ax1.xaxis.set_major_formatter(tick_formatter)\n",
    "#ax1.set_title('Number of Documents by Dominant Topic', fontdict=dict(size=10))\n",
    "#ax1.set_ylabel('Number of Documents')\n",
    "#ax1.set_ylim(0, 1000)\n",
    "\n",
    "# Topic Distribution by Topic Weights\n",
    "#ax2.bar(x='index', height='count', data=df_topic_weightage_by_doc, width=.5, color='steelblue')\n",
    "#ax2.set_xticks(range(df_topic_weightage_by_doc.index.unique().__len__()))\n",
    "#ax2.xaxis.set_major_formatter(tick_formatter)\n",
    "#ax2.set_title('Number of Documents by Topic Weightage', fontdict=dict(size=10))\n",
    "\n",
    "#plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
